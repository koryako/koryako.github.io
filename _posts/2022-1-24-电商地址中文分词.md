---
layout: post
title: "地址分词"
subtitle: '中文地址分词，ner'
author: "koryako"
header-style: text
tags:
  - 地址分词
---

地址分词
---



https://github.com/geeklili/albert-finetune



google 的bert 预训练模型[bert 源码解读] https://www.jianshu.com/p/3d0bb34c488a   ,她的中文变体 albert 和roberta都是在其源码的基础上改造而成，并使用中文语料重新训练而成

我们使用 [基于BERT预训练的中文命名实体识别TensorFlow实现](https://blog.csdn.net/macanv/article/details/85684284)[源码](https://github.com/macanv/BERT-BiLSTM-CRF-NER)  进行实际的部署， 他的tf2.0 代码  可以[参考 2.0 代码](https://github.com/StanleyLsx/entity_extractor_by_ner) 




1. https://github.com/google-research/bert#fine-tuning-with-bert （谷歌开源BERT）

2. https://blog.csdn.net/macanv/article/details/85684284 （基于BERT预训练的中文命名实体识别TensorFlow实现）

3. https://www.jianshu.com/p/b05e50f682dd（序列标注——实体识别BERT-BLSTM-CRF）

4. https://www.jianshu.com/p/3d0bb34c488a（BERT的demo运行）

5. https://python.ctolib.com/ProHiryu-albert-chinese-ner.html（使用预训练语言模型ALBERT做中文NER）

6. https://github.com/kyzhouhzau/BERT-NER（输出带acc）

7. https://github.com/brightmart/albert_zh（ALBert 预训练模型）

8. https://github.com/macanv/BERT-BiLSTM-CRF-NER（BERT-BiLSTM-CRF-NER常用版）

9. https://www.jianshu.com/p/1d6689851622（五分钟搭建一个基于BERT的NER模型）

10. https://github.com/BrikerMan/Kashgari（快速搭建NER框架）

11. https://github.com/grallage/ALBERT-BiLSTM-CRF-NER（ALBERT-BiLSTM-CRF-NER）

